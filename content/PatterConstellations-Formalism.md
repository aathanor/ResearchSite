---
title: "1. Pattern-Recognition Unity: Dissolving the Pattern/Recognition Distinction"
author: Florin Cojocariu
tags: ["pattern-constellations", "pattern-recognition-unity"]
lens: ["philosophy", "cognition"]
status: "developing"
date: 10.28.2025
---

# Abstract

What happens when we recognize something? Standard accounts treat "pattern" and "recognition" as distinct stages: first a pattern is detected, then it is recognized and triggers a response. I argue that this sequential model is misleading. The separation exaggerates a serial logic that does not match how recognition actually occurs.[^23]

I propose Pattern-Recognition Unity (PRU). On PRU, recognition is the simultaneous activation of an integrated Pattern-Constellation—a single event in which perceptual patterns, motor readiness, affective responses, and linguistic associations co-occur. Recognizing your cat is not a visual trace followed by later reaction; it is one unified activation that includes seeing, feeling, and readiness to act.

Three kinds of evidence support this. First, how recognition actually feels—immediate, not sequential. Second, neuroscience shows early co-activation across brain regions. Third, computational models (Hopfield networks, transformer architectures) demonstrate that unified activations are both learnable and efficient. This perspective dissolves several philosophical problems: the symbol-grounding problem (words are part of sensorimotor constellations rather than disconnected symbols) and the binding problem (perceptual, motor, and affective patterns need not be stitched together post hoc).

This work develops the conceptual claim, sketches models, and identifies testable predictions about early co-activation. PRU offers a simpler, more unified framework for thinking about recognition in philosophy, cognitive science, and AI.

We proceed in two parts. Part 1 (PATTERNS) deals mostly with pre-verbal cognition and establishes the general framework: Pattern-Constellations (PCs) as integrated assemblies of perceptual, motor, emotional, and other patterns that activate simultaneously. Part 2 (LANGUAGE) applies this framework to language, showing how linguistic patterns develop through embodied learning and how reference emerges through usage-based coordination rather than rule-based mapping.

# PART 1: PATTERNS

## The Hidden Structure of Recognition

Humans learn through co-occurring, multi-modal regularities. I call these _Pattern-Constellations_ (PCs): assemblies that contain perceptual, motor, linguistic, and emotional patterns. What we call a "pattern" in cognition is actually multiple pattern-types that arise and function together. The term captures the distributed-yet-unified neural architecture that simple "pattern" obscures. Pattern-Recognition Unity (PRU) hypothesizes that what we call "recognition" is the _parallel_ activation of a PC: perception and response are simultaneous aspects of the same dynamical event, not a serial pipeline from detection to reaction. This paper defends PRU conceptually, sketches its computational realizations, and gives empirical predictions that distinguish it from traditional pattern-matching models.

_A concrete example:_ When you see your cat, what actually happens? Not in sequence, but all at once:

* Visual patterns activate (shape, size, movement style)
* Motor patterns activate (petting gestures, approach behaviors)
* Emotional patterns activate (affection, playfulness)
* Auditory expectations activate (meowing, purring)
* Linguistic patterns activate ("kitty," pet-related expressions)
* Memory patterns activate (feeding times, favorite spots)

These don't link together after arising separately. They activate as one unified Pattern-Constellation. What we call "recognition" is just an ensemble of patterns that co-emerges when its visual part is activated. Neuroscience confirms this: language areas fire during action observation, motor areas activate when processing action verbs, emotional centers participate directly in perception. The learned patterns were never separate—they arose together during learning and remain together in recognition.

## Pattern-Matching vs Pattern-Recognition: Serial vs Parallel

Our first error is a category error: conflating two fundamentally different phenomena. The distinction is not primarily temporal but logical:

**Pattern-matching** is serial through logical dependency—each step cannot begin until the previous step completes:

* Finding the right key: try one, compare, reject, try next
* Solving an equation: step by step manipulation where each transformation depends on the previous
* Following GPS directions: sequential decision points that must be processed in order
* Logical reasoning: if-then-therefore chains where conclusions require premises

**Pattern-recognition** is parallel through logical independence—all components activate simultaneously without waiting for others:

* Seeing your mother's face: instant, complete activation of visual, emotional, and motor patterns
* Understanding a word: meaning, pronunciation, and associations arrive together
* Catching a ball: hand positioning, grip preparation, and body adjustment happen as one
* Recognizing danger: fear and readiness arise together

Note that even "instantaneous" parallel processes have temporal micro-structure at neural timescales, but they lack the logical dependencies that define serial processing. In pattern-recognition, all aspects of the constellation become available simultaneously, even if cortical inhibition prevents some components (like motor actions) from executing. In pattern-matching, a new step has to wait for the previous step to complete, so there is _no simultaneous availability_.

Why do we conflate them? Because conscious thought IS serial pattern-matching. Logic, language, and reasoning operate through sequences: cause-then-effect, premise-then-conclusion, if-then-therefore. The idea of an "explanation" itself involves a narrative of some sort that exposes an argument in a step by step fashion. This default reasoning serial nature makes us experience everything as sequential, including recognition—which isn't sequential at all.

There is more to say on the "cause and effect" paradigm: we learn, from an early age, that everything has a cause which _precedes_ the effect. But as Bertrand Russell noted, there's no "cause and effect" in physical equations—F=ma doesn't say force causes acceleration or acceleration causes force. The equation describes a unified relationship. Similarly, Pattern-Constellations don't have perception causing reaction. The constellation IS both simultaneously.

Our thinking imposes sequence on what isn't sequential. We experience "see cat THEN feel affection THEN reach to pet" because that's how serial consciousness narrates parallel events. But the cat-constellation activated whole—seeing, feeling, and reaching-readiness arose together. The sequence exists in our conscious narrative, not in the constellation activation itself. This phenomenological seriality emerges through selective inhibition: the constellation activates as a whole, but cortical inhibition can suppress motor components while allowing sensory components to reach consciousness, creating the illusion of sequence.

## Patterns of Reaction

Our second error is conceptual: what we call "pattern" typically refers to perception-side patterns (visual, auditory, tactile, intellectual). What we call "recognition" typically refers to reaction events (motor, emotional, linguistic responses). To us, to accept that someone recognizes something, a _reaction_ is needed; in fact we cannot separate "reaction" and "recognition". But to have proper recognition of similar objects, the reaction should be similar in every case, i.e. reaction itself follows a pattern. Perception-patterns and reaction-patterns are ALL patterns, learned together—just different types within the same constellation.

Consider learning about hammers. Traditional models might suggest a child first acquires visual templates, then separately learns motor movements, then adds emotional associations, then attaches linguistic labels. An alternative developmental account suggests these aspects develop as integrated wholes through embodied interaction:

* Visual/tactile patterns (shape, weight, texture)
* Motor patterns (grasping, swinging, striking motions)
* Functional patterns (hitting nails, building, tool use)
* Emotional patterns (satisfaction, frustration)
* Social patterns (collaboration, approval)
* Linguistic patterns (the word "hammer," metaphorical uses)

This is more clear if we think of driving or playing tennis: we learn the visual _and_ motor patterns _together_. You do not learn first that "when ball slowly gets into the driveway, a child will follow" and then "when child in driveway, hit brakes". This is why when you drive _you do not drive using thinking_.[^14]

When you "recognize" your cat, you're not detecting a pattern and then generating a response. The entire cat-constellation activates, containing both perception-patterns and reaction-patterns. Your brain may inhibit certain reaction-patterns (you don't always pet every cat you see), but they're all immediately _available_. The "recognition" IS the constellation activation itself.

Consider this: Can you have recognition without a pattern to recognize? No, because then, what exactly will you recognize? Can a pattern exist without being recognized? No—an unrecognized "pattern" is just undifferentiated flux, if there is no brain to recognize it, how you would call it a pattern?[^15]

Like "buyer" and "seller" are abstractions from the more fundamental transaction, "pattern" and "recognition" are abstractions from Pattern-Constellation Activation, the more fundamental event. If there is no transaction, it makes no sense to talk about a buyer and a seller. If there is no Pattern-Constellation Activation, it doesn't make sense to talk about 'pattern' and 'recognition'.

## The Phenomenology of Recognition

When you see a friend's face across a crowded room, recognition is immediate. No conscious search through memory files. No step-by-step matching. The recognition just appears, complete.

Compare this to struggling to remember where you know someone from. That's effortful, takes time. Instant recognition of your childhood friend is different—immediate, effortless.

What does "recognize" mean? When I recognize a cat, what becomes available? Petting gestures, expectation of meowing, wariness of scratching, affection or playfulness, the word "cat," associations about where cats sleep and eat.

A constellation of patterns becomes immediately available. Sensory patterns, motor patterns, emotional patterns, linguistic patterns.

This constellation doesn't become available _after_ recognition. It IS recognition. The immediate availability of this readiness-constellation is what we call recognition.

Recognition is not: identify visual pattern, then trigger responses. Recognition is: the immediate constellation of readiness becoming available. They're the same event. No temporal sequence of "visual input → memory search → recognition achieved." The constellation-activation IS the recognition.

This is a simple idea but one that goes so much against our intuition that it deserves insisting on, before moving on. So:

Recognition is not the identification of a visual pattern that then triggers responses. Rather, recognition IS this immediate constellation of readiness becoming available. The recognition and the readiness are not sequential—they are the same event. This would explain the experiential immediacy: there is no process of matching followed by retrieval of appropriate responses. The constellation of readiness IS what recognition is, not what recognition produces. There's no temporal sequence of "visual input → memory search → recognition achieved." Instead, the entire constellation becomes simultaneously "close to hand," and that constellation-activation IS the recognition event.

## Pattern recognition: the actual view

In cognitive theories, pattern recognition has been defined as "the ability to abstract and integrate certain elements of a stimulus into an organised scheme for memory storage and retrieval" (Solso, 1998). Serial processing is assumed everywhere.

# Pattern-Recognition Unity (PRU)

**The PRU Thesis**: What we call "pattern" and "recognition" are not two events—one perceptual, one responsive—but unified aspects of Pattern-Constellation activation, one **atomic event**. These Pattern Constellations (PC) are the fundamental cognitive blocks: when we learn things, PCs are created. What we call "recognition" is the _parallel_ activation of a PC: perception and response are simultaneous aspects of the same dynamical event, not a serial pipeline from detection to reaction.

# Neural Evidence for Pattern-Constellations

Neuroscience reveals that neural systems operate through constellation-activation rather than sequential processing. The most direct support comes from studies of unconscious neural processing, which consistently show that specific response circuits activate before conscious awareness of stimuli.

While Libet's experiments examined self-initiated action rather than stimulus recognition, they establish the broader principle that neural preparation precedes conscious awareness—challenging any model that assumes conscious recognition must precede response readiness. Libet's classic experiments revealed that motor readiness potentials begin 350-500ms before people report being aware of their intention to move. Similarly, the amygdala responds to threatening faces presented too briefly for conscious recognition, around 30ms, and subliminal words activate semantic networks and motor areas before conscious identification.

This temporal evidence directly challenges traditional models where recognition precedes response preparation. Instead, it supports PRU's claim that recognition IS immediate constellation-activation. When you see a cat, petting readiness, emotional responses, and approach behaviors are already activated before conscious awareness that you've "recognized" a cat. There's no temporal gap because the constellation-activation IS the recognition event, not something that produces recognition.

Additional evidence comes from research showing neural integration across modalities. Studies demonstrate that seeing action verbs, such as 'kick' or 'lick,' elicited similar brain activation patterns in the motor and premotor areas compared to the actual movements the words referred to. Similar findings exist across modalities, with sensorimotor areas involved in perception and action overlapping with brain regions that are active during language comprehension.

These findings converge on a picture where recognition is not pattern-matching but constellation-activation—supporting PRU's dissolution of the recognition process into immediate readiness-availability. Word-patterns, action-patterns, and sensory-patterns involve genuinely integrated neural networks rather than separate systems that become associated.

# Pattern-Constellations and Neural Networks

The concept of Pattern-Constellation is very relevant to a type of neural network (NN) that resembles more closely biological NNs than any other: Hopfield Networks with Hebbian Learning. A Hopfield Network is a weighted network (links between nodes can have different weights, including 0) that is trained using the Hebbian principle: "what fires together, links together". Their main application is in memory, because it was discovered that HNs are really good at quickly learning patterns of input and recognize them even from incomplete input. We'll get back to the connection between memory and pattern-recognition, but for now let's see why Pattern-Constellations are essential to understanding these networks.

In Hopfield Networks with functional specialization, we can literally observe Pattern-Constellation structure emerge. When we designate some neurons as visual, others as motor, and others as emotional, and train the network on experiences, we see something remarkable: learning creates constellations that span all these areas. When a learned input is presented, neurons from visual, motor, and emotional areas fire together as a unified assembly. This isn't metaphorical—it's the actual neural organization that emerges from Hebbian learning.

Taking an example will help. Let's consider a 256-neuron HN, where 25 of them are input neurons. At first, the remaining 231 neurons are not differentiated, and Hebbian learning happens in the same way: in training, link weights are adjusted and pruned (weight = 0), and after becoming stable, we end with a sparse network (not all nodes connected to each node). But we know that biological NNs are not uniform; there is a lot of specialization and _locality_ in brains of all types: there are motor areas, vision areas, language areas, etc. We can do the same with our HN, and create _functional groups of neurons_: the first 25 are visual neurons from above, 131 of them are motor neurons (and their output is movement), and 100 are emotional neurons (and their output is in the range "good/bad" as "pleasure/pain"). Now we have a primitive organism able to learn and react, if we endow it with some form of innate learned patterns (like those all animals born with). One such innate rule is to search pleasure (get closer to pleasure producing objects) and avoid pain (run away from pain producing objects).

# Memory and Pattern Constellations
(to be done)

# How Animals and LLMs Navigate Reality

A frog's eye does not, in practice, detect a "fly-pattern" and then separately trigger a "tongue" program. The fly-constellation includes both the visual signature **and** the tongue-strike readiness as a single dynamical event; sensory input rapidly engages sensorimotor circuits already biased toward the appropriate response. This is why biological reactions can be so fast and appropriate—there need not be a long serial delay between perception and action readiness.

The difference between primitive automatic responses and controlled behavior lies not in the constellation structure but in inhibition mechanisms:

* **Primitive/automatic**: Full constellation activation without inhibition (snake → instant jump)
* **Controlled/conscious**: Constellation activation with selective inhibition, allowing some components to reach consciousness while suppressing others

This framework explains why practiced behaviors become "automatic"—we're reducing inhibition and allowing fuller constellation expression. It also explains the phenomenology of conscious control: what we call "deciding" to act is often the release of inhibition on motor patterns that were already activated as part of the recognition constellation.

# Position in Current Research

Several research programs address related issues. Embodied cognition shows sensorimotor activation during language processing. Enactivism rejects internal representations. Predictive processing offers accounts of neural prediction. But most retain the pattern/recognition split in some form.

# Parallel vs Serial Processing in AI Systems

Large Language Models experience parallel perception. When receiving a prompt, there's immediate constellation-activation of context and response patterns. The recognition is instantaneous.

Humans are constrained by serial language absorption. When reading, you build context incrementally because language unfolds in time. The "I get it" moment comes when enough context accumulates for the pattern-constellation to activate.

But your "I get it" moment IS the same instantaneous pattern-recognition that LLMs experience. The gradual buildup isn't slow recognition. It's preparation for recognition, which then happens all at once.

# The Key-Lock Solution to AI Understanding

This framework dissolves the puzzle of LLM "understanding". When an LLM produces responses that fit philosophical questions precisely, it's performing sophisticated pattern-constellation recognition (although in this case, the constellation does not involve motor and feeling patterns, just different dimensions of the linguistic landscape). The prompt is a conceptual key that activates specific regions in the model's text-pattern landscape, generating the corresponding lock—the patterns that belong in that conceptual space.

The fit is what humans interpret as "understanding," but PRU suggests human understanding works the same way: recognizing where arguments fit in your constellation of conceptual patterns and activating appropriate response patterns. The sophistication of the pattern-matching creates the appearance of a fundamentally different cognitive process, when it might just be constellation-activation at scale.

The question shifts: why did we think understanding was something beyond pattern-recognition? LLMs don't possess mysterious understanding. They demonstrate what cognition looks like freed from serial processing constraints.

Transformers show PRU at work during inference. Their forward pass computes attention maps whose interactions produce contextualized activations in parallel, before any serial decoding. This implements simultaneous activation.

But training breaks PRU. Standard backpropagation is global optimization, materially different from local associative plasticity. PRU claims recognition and learning should be continuous: the same locally-driven dynamics that produce recognition should sculpt the connections making future recognitions possible. Transformers exemplify forward-pass unity at inference, but their backprop training doesn't satisfy learning-unity.

At inference, transformers behave like PRU predicts. When GPT answers "What are the main ideas in Wittgenstein's work?" the prompt doesn't invoke a separate search-then-match subroutine. Attention concurrently activates a constellation of candidate continuations. The network selects among them in a subsequent decoding step.

This is why LLMs seem to understand without understanding. They're not reasoning from perception to response. They're activating unified pattern-constellations where appropriate responses are already present.

# Why Current AI Struggles

Transformers violate Pattern-Recognition Unity through backpropagation training. While they achieve parallel pattern-constellation activation through attention mechanisms, backpropagation reintroduces serialization: compute error, then propagate backwards layer by layer. This breaks the unity that makes the architecture powerful and makes training expensive.

Hopfield Networks with Hebbian Learning demonstrate pure PRU learning is possible. With 256 neurons using local, correlation-based Hebbian learning, they maintain pattern-recognition unity throughout. No sequential error propagation, no artificial separation of pattern and recognition. The constellation activation that constitutes recognition is the same dynamics that drives learning.

The principle is simple: systems that maintain PRU throughout should exhibit different capabilities than systems that break unity for training. Not better or worse, but qualitatively different—like the difference between how animals navigate space and how GPS systems compute routes.

# Philosophical Dissolutions

Pattern-Constellation Unity dissolves several classical problems.

**The Symbol Grounding Problem**: Linguistic patterns develop as integrated aspects of sensory-motor-emotional constellations, not as separate symbols requiring grounding. Words don't need to connect to things. Word-patterns are already part of integrated constellations that, for our consciousness, are the things. The word "hammer" doesn't refer to hammer-experience. It's one linguistic pattern within the hammer-constellation that also has sensing, motor, and feeling patterns.

**Primitive Reference**: Traditional approaches assume words must hook onto objects in the external world. This leads to infinite regress—what grounds the grounding relation itself? Tarski proposed: "Snow is white" is true if and only if snow is white. Field's concern: the right side appears to be just more words with no primitive reference to actual snow. Where's the connection to the external world?

The problem dissolves when we recognize that linguistic expressions aren't disconnected words floating in semantic space. Word-patterns exist integrated with sensation-patterns within the snow-constellation. This constellation includes visual patterns (white color, crystalline structure), tactile patterns (cold, wet, granular), motor patterns (scooping, throwing, building), emotional patterns (winter joy, coldness), and word-patterns ("snow," "white," "cold," "winter"). The word-patterns are part of this integrated constellation, not separate symbols that need to refer to it.

**Consciousness**: Not "How does neural activity generate subjective experience?" but "How do Pattern-Constellations become aware of their own activation?" A cat's mouse-constellation activates without meta-recognition. Human consciousness is Pattern-Constellations recognizing their own constellation-nature, combined with sophisticated inhibition mechanisms that selectively activate components, creating the experience of choice and deliberation.

**The Binding Problem**: How does the brain integrate separate sensory features—color, shape, motion, location—processed in distributed areas into a single coherent perception? When seeing a red ball rolling, the brain must bind redness with roundness and motion. But no mechanism needs to bind distributed patterns into unified percepts. The constellation is the unified percept. We only look for binding mechanisms because we assumed the patterns were separate.

**Free Will**: Conscious control might be the ability to inhibit parts of pattern-constellations while allowing others to activate. Free will becomes not generating novel responses ex nihilo, but selectively inhibiting or releasing pre-existing constellation components. The experience of choosing emerges from selective inhibition and release within already-activated constellations.

**The Frame Problem**: How does an agent determine relevance context-sensitively? PRU proposes relevance is intrinsic to pattern-constellations through embodied developmental history, not computed algorithmically. Dreyfus argued the frame problem reveals a fundamental limitation: context-sensitive relevance cannot be captured through rules or algorithms but emerges from embodied engagement with situations.

# The Deeper Implications

Pattern-Constellation Activation is the fundamental phenomenon. Not patterns being recognized, not recognition of patterns, but unified constellation events we've mistakenly divided into perceptual and responsive aspects.

PRU and Pattern-Constellations work best for pre-verbal cognition. Animals live and perceive locally. But the linguistic space is by nature global. Transformers may be better at learning it because the locality of PRU can't be efficient there.

The serial nature of reasoning and language explains why dualistic thinking feels natural. We're conscious only of our serial pattern-matching, not the parallel pattern-recognition enabling it. We narrate unified events as sequences because narrative is sequential. But catching a ball, recognizing faces, understanding words—these demonstrate the deeper parallel reality our serial thinking obscures.

The solution isn't adding new explanations. It's recognizing that Pattern-Constellations are fundamental. Everything else—patterns, recognition, stimulus, response, cause and effect—are conceptual divisions we've imposed on unified constellation events. Like discovering space-time, we're not solving the pattern-recognition problem but seeing there was never separation to explain.

# References
(NB: provisional list not proper bibliography; part of the titles already used and to be added in text, part skimmed not deeply engaged yet, part of them just reading list)

**Primary Sources**

==Philosophy==

Chalmers, D. J. (1995). Facing up to the problem of consciousness. Journal of Consciousness Studies, 2(3), 200–219.

Dennett, D. C. (1984). Cognitive wheels: The frame problem of AI. In Minds, Machines and Evolution (pp. 129–151). Cambridge University Press.

Field, H. (1972). Tarski's theory of truth. The Journal of Philosophy, 69(13), 347–375.

Fodor, J. A. (1975). The language of thought. Harvard University Press.

Harnad, S. (1990). The symbol grounding problem. Physica D: Nonlinear Phenomena, 42(1-3), 335–346.

Heidegger, M. (1927/1962). Being and time (J. Macquarrie & E. Robinson, Trans.). Harper & Row.

Kant, I. (1781/1998). Critique of pure reason (P. Guyer & A. W. Wood, Trans.). Cambridge University Press.

Merleau-Ponty, M. (1945/2012). Phenomenology of perception (D. A. Landes, Trans.). Routledge.

Tarski, A. (1944). The semantic conception of truth: And the foundations of semantics. Philosophy and Phenomenological Research, 4(3), 341–376.

==Cognition==

Barsalou, L. W. (1999). Perceptual symbol systems. Behavioral and Brain Sciences, 22(4), 577–660.

Chemero, A. (2009). Radical embodied cognitive science. Review of General Psychology, 13(4), 323–330.

Gibson, J. J. (1979). The ecological approach to visual perception. Houghton Mifflin.

Glenberg, A. M. (1997). What memory is for: Creating meaning in the service of action. Behavioral and Brain Sciences, 20(1), 41–50.

Varela, F. J., Thompson, E., & Rosch, E. (1991). The embodied mind: Cognitive science and human experience. MIT Press.

==Computer Science==

Marr, D. (1982). Vision: A computational investigation into the human representation and processing of visual information. MIT Press.

McCarthy, J., & Hayes, P. J. (1969). Some philosophical problems from the standpoint of artificial intelligence. Machine Intelligence, 4, 463–502.

Newell, A., & Simon, H. A. (1972). Human problem solving. Prentice-Hall.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … & Polosukhin, I. (2017). Attention is all you need. Advances in Neural Information Processing Systems, 30.

**Secondary Sources**

==Philosophy==

Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. Behavioral and Brain Sciences, 36(3), 181–204.

Cojocariu, F. (2025). Patterns, pragmatism, and mild realism: An empirical probe. [Essay for Modern Metaphysics Class]

Dreyfus, H. L. (1992). What computers still can't do: A critique of artificial reason. MIT Press.

Hohwy, J. (2013). The predictive mind. Oxford University Press.

Kiverstein, J., & Miller, M. (2015). The embodied brain: Towards a radical embodied cognitive neuroscience. Frontiers in Human Neuroscience, 9, 237.

Wilson, M. (2002). Six views of embodied cognition. Psychonomic Bulletin & Review, 9(4), 625–636.

==Cognition==

Dehaene, S., Naccache, L., Le Clec'H, G., Koechlin, E., Mueller, M., Dehaene-Lambertz, G., … & Le Bihan, D. (1998). Imaging unconscious semantic priming. Nature, 395(6702), 597–600.

Friston, K. (2010). The free-energy principle: A unified brain theory? Nature Reviews Neuroscience, 11(2), 127–138.

Gallese, V. (2003). The roots of empathy: The shared manifold hypothesis and the neural basis of intersubjectivity. Psychopathology, 36(4), 171–180.

Libet, B., Gleason, C. A., Wright, E. W., & Pearl, D. K. (1983). Time of conscious intention to act in relation to onset of cerebral activity (readiness-potential): The unconscious initiation of a freely voluntary act. Brain, 106(3), 623–642.

Morris, J. S., Öhman, A., & Dolan, R. J. (1998). Conscious and unconscious emotional learning in the human amygdala. Nature, 393(6684), 467–470.

Nakamura, K., Dehaene, S., Jobert, A., Le Bihan, D., & Kouider, S. (2007). Automatic activation of motor programs by auditory perception of action sounds. NeuroImage, 37(2), 564–575.

Pulvermüller, F., & Fadiga, L. (2010). Active perception: Sensorimotor circuits as a cortical basis for language. Nature Reviews Neuroscience, 11(5), 351–360.

Rizzolatti, G., Fogassi, L., & Gallese, V. (2001). Neurophysiological mechanisms underlying the understanding and imitation of action. Nature Reviews Neuroscience, 2(9), 661–670.

Sato, W., Kochiyama, T., Uono, S., Matsuda, K., Usui, K., Inoue, Y., & Toichi, M. (2024). Sensorimotor simulation semantics: Grounding linguistic meaning in sensory and motor experience. Nature Human Behaviour, 8, 1–15.

Whalen, P. J., Rauch, S. L., Etcoff, N. L., McInerney, S. C., Lee, M. B., & Jenike, M. A. (1998). Fear and the human amygdala. Journal of Neuroscience, 18(1), 411–418.

==Computer Science==

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., … & others. (2020). Language models are few-shot learners. Advances in Neural Information Processing Systems, 33, 1877–1901.
LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444.

Shanahan, M. (2024). Talking about large language models. Communications of the ACM, 67(2), 68–79.

[^14]: Incidentally, this offers a better explanation for the problem of automatic processing than most modern theories of cognition that struggle because of their serial models.

[^15]: This devolves into a complicated discussion about realism and anti-realism in patterns, one started by the Dennett and Nelkin papers, but for now it helps to observe that patterns are mental events. The difficulty here is to clarify what we call "reality", once we adopt a definition, the realist/anti-realist debate settles _within that respective definition_. For me, for something to be real it is important to have _proof_ it is real, and proofs are mental objects, not natural ones. Another angle is that of _learning_: in order to recognize a pattern, some sort of learning should precede it; no learning, no pattern. But learning does not happen in the world learned about, but in our minds.

[^16]: The conceptual difficulty behind the very simple claim of PCU is not so different from the one in Special Theory of Relativity. STR is built from a very simple, although shocking, observation: there is no simultaneity possible if the speed of light is finite. While the final argument that space and time are unified is simple, almost everyone when trying to understand it has, at first, a serious difficulty which stems from the _categorical error_ of learning and treating them as different.

[^17]: There is abundant neurosciences literature documenting these claims, with Libet et al. (1983), Sato et al. (2024) and Pulvermüller & Fadiga (2010) being some of the most well known. The neurological evidence for PRU is a connected research field but it must be said our approach is and needs to stay philosophical: PRU has important consequences in the Philosophy of Language, Reference Theory and the way we understand LLMs and AI in general.

[^18]: This difference illuminates why LLMs can exhibit apparently immediate pattern-recognition. While LLMs use probabilistic mechanisms during response generation, their transformer architecture processes contextual information in parallel rather than through sequential search during the recognition phase. The way we use language in conversation (question/response) may involve similar pattern-constellation activation, where word patterns activate alongside action/feeling/sensorial patterns in integrated networks.

[^21]: One interesting parallel is that abstract learning (using language as abstraction) requests extremely elaborate and intensive training in humans, taking decades to complete, while practical tasks (like riding a bicycle) can be very fast by comparison. This suggests that while PRU and PCs are better models for non-verbal learning, verbal learning _does need_ a more complex, global and intensive model. This is maybe the reason transformers are good at text. However, AI is not limited to LLM and, moreover, AGI is not _only_ about language.

[^22]: The "causation irrationality" problem starts with Hume and gets its final blow in Russell's paper on causation. But, in the end, isn't it that causation is just some serial thinking splitting a unified event into bits, only to be able to _describe them_?

[^23]: question:Asta ar fi o întrebare. Poate fi ștearsă. (click pe edit):florin.cojocariu@s.unibuc.ro:1761823715499:What happens when we recognize something? Standard accounts treat "pattern" and "recognition" as distinct stages\: first a pattern is detected, then it is recognized and triggers a response. I argue that this sequential model is misleading. The separation exaggerates a serial logic that does not match how recognition actually occurs.