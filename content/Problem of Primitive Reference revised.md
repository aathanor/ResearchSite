---
title: "3. The Problem of Primitive Reference: A Pattern-Constellation Approach" 
author: Florin Cojocariu 
date: 09.30.2025
---

# Field's Challenge

Tarski's truth definition looked like a breakthrough. Before Tarski, positivists worried that semantic notions like "true" and "refers" might be metaphysical holdovers with no place in science. Tarski showed how to define truth for formal languages using only logic and set theory. Popper reported that thanks to Tarski, philosophers "no longer hesitate to speak of truth."

But Hartry Field saw a problem everyone else missed.

Tarski defines truth for sentences in terms of simpler semantic notions: reference (denotation) and satisfaction. A sentence like "Socrates is wise" is true if and only if the name "Socrates" denotes Socrates and the predicate "wise" applies to him. The recursive clauses show how complex sentences inherit their truth-values from simpler parts. This is elegant formal machinery.

Field's objection cuts through the elegance. Tarski "succeeded in reducing the notion of truth to certain other semantic notions" without explaining those notions themselves. The base clauses of Tarski's definition simply list what names denote and what predicates apply to: "'Socrates' denotes Socrates," "'F' is true of all and only Fs." These clauses don't explain what makes those words denote those things. They assume it.

The mystery hasn't disappeared. It moved from "true" to "denotes" and "satisfies." Field's diagnosis: Tarski's accomplishment should make "'true' acceptable only to someone who already regarded these other semantic notions as acceptable."

## The Physicalist Demand

Field's worry isn't merely technical. It's rooted in physicalism - the view that everything is ultimately physical. If you accept physicalism, you face a constraint: explain how words hook onto world using only physical-causal terms, or eliminate semantic talk altogether.

Field calls the opposing view "semanticalism" - the doctrine that reference is an irreducible primitive fact that cannot be explained in non-semantic terms. The fact that "Schnee" refers to snow would just be a brute semantic fact, requiring no further explanation.

This is unacceptable to Field for the same reason vitalism was unacceptable in biology. Vitalists posited a primitive "life force" that couldn't be explained in physical-chemical terms. Physicalists rejected vitalism not because they denied life exists, but because they demanded explanation of vital phenomena in physical terms. The triumph of molecular biology was showing how metabolism, reproduction, and inheritance emerge from physics and chemistry without any primitive life-force.

Field sees semanticalism as parallel to vitalism and Cartesian dualism (which posits irreducible mental substance). "As a physicalist I believe that all three doctrines must be rejected." A physicalist "doesn't want to say that it is a primitive and inexplicable fact" that certain utterances are true or that certain words denote certain things.

The demand is clear: either explain reference in naturalistic terms or eliminate it. Field rejects elimination - semantic notions are too useful. That leaves naturalization.

## What Would Solve It

Field sketches what a solution would look like. Classical descriptivist theories tried to reduce reference through analytic definition - "Aristotle" abbreviates something like "the teacher of Alexander who wrote the Metaphysics." This approach failed. We can refer to things we can't define. Reference doesn't work through description.

More promising are causal theories, developed by Kripke and Putnam around the same time. The name "Cicero" refers to Cicero because of a causal-historical chain connecting current uses back to an initial dubbing of that person. Natural kind terms like "water" or "muon" refer through causal interactions with those kinds - perception, investigation, detection. These theories attempt to explain reference using only physical-causal relations, communication practices, and social transmission.

Field sees "some hope for a physicalistic reduction of denotation" in causal theories. But he recognizes complications: indeterminacy (does "mass" in pre-relativistic physics refer to rest mass or relativistic mass?), partial denotation, reference to non-existent things. A full theory will be "empirical and semantical" - it will require substantial work in psychology, neuroscience, and linguistics. Field expected that "psychological models of human beings and investigations of neurophysiology will be very relevant to discovering the mechanisms involved in reference."

The problem of primitive reference is a scientific problem, not just armchair philosophy.

## Mental Representation

In 1978, Field extended his approach to mental states. If beliefs and desires are "about" things, what makes them so? This is intentionality - the mental analog of linguistic reference.

Field's proposal: analyze belief as a two-part relation. "X believes that P" means X has an internal mental representation S that means P, and X accepts S. This splits intentionality into two problems: how brain states function as representations (a question for cognitive psychology), and how those representations get semantic content (the same reference problem, now for mental symbols).

Field argued that a correspondence-based semantics for mental representations "is the best hope" for a materialistic theory of mind. A mental symbol might refer to water because water in the environment causally regulates when that symbol activates. The Tarskian truth-definition extends into the mind, treating mental representations as an internal language whose primitive terms need reference explained naturalistically.

## Evolution and Deflation

Field's views evolved. By the 1980s and 1990s, he adopted a deflationary stance toward truth. Truth isn't a substantial property requiring deep metaphysical analysis. Asserting "'P' is true" just serves to endorse P or generalize over propositions. Truth is a logical device with no deep nature beyond the T-schema.

But Field didn't become deflationary about reference. Deflating truth doesn't eliminate the need to explain how assertions connect to the world. Even if truth adds nothing metaphysically, we still need an account of belief, assertion, and semantic content. Field continued to demand naturalistic explanation of reference and intentionality.

The key analogy: valence in chemistry and genes in biology. These concepts were useful and well-understood before anyone reduced them to physics. But their acceptability in a physicalist framework remained in question until reduction was achieved. Valence got explained through electron configurations, genes through DNA. The fruitfulness of these concepts suggested physical mechanisms underneath.

Field sees semantic notions the same way. Their usefulness in communication and inquiry gives us reason to think they're explicable in physical terms. "Insofar as semantic notions like 'true' are useful, we have every reason to suspect that they will be reducible to non-semantic terms."

This is the challenge: provide that reduction, or risk forfeiting semantic notions in a scientific worldview.

# The Pattern-Constellation Response

Field's challenge demands naturalistic explanation of reference. The Pattern-Constellation (PC) framework provides one, but not by constructing a bridge from words to world. The bridge metaphor itself is the problem.

## The Bridge Assumption

Most theories of reference assume a task: connect linguistic items (words, concepts) to worldly items (objects, properties). These seem like different kinds of things, separated by a gap. The puzzle becomes: how to span that gap?

Causal theories posit causal chains. Descriptivist theories posit conceptual links. Intentional theories posit mental directedness. But all assume the same basic structure - two separate domains needing connection.

PC rejects this assumption. Reference isn't a bridge because there's no gap to span. What we call "reference" is an internal coordination within a learned representational system, not a connection between fundamentally distinct types of things.

## Recognition as Primitive

Start with pattern recognition. When you see a duck (looking at the duck-rabbit illusion), what happens? Standard view: there's a pattern "duck" that exists independently, and you recognize it. Pattern and recognition are two separable things.

PC claims this is wrong. Pattern and recognition are phenomenologically unified. There is no duck-pattern you then recognize. There is only the atomic event of duck-seeing. This is Pattern-Recognition Unity (PRU).

The argument: when a duck-pattern activates, your entire constellation of duck-associated elements activates simultaneously - visual features, motor responses, affective reactions, linguistic labels. Recognition just is this activation. It's absurd to speak of recognizing without reacting, and the reactions are part of what the pattern is. Pattern and recognition aren't two things but one.

Consider it computationally. In pattern-matching systems (traditional AI), you store templates, then search through them serially when input arrives. But biological pattern recognition works through parallel activation - the whole constellation lights up at once. A duck visual pattern doesn't exist separately anywhere in the network. The pattern is the low-energy attractor state that the system falls into. You can't locate "where the duck image is stored" because duck-visual neurons never fire alone. Pattern exists in its recognition.

Pre-linguistic creatures prove the point. A cat recognizing a mouse has an integrated sensory-motor-emotional constellation, not a representation plus separate recognition process. Recognition triggers hunting immediately. The response is part of what recognition is.

What looks like "stored pattern" is really dispositional structure - connection weights that produce coordinated activation when triggered. The network stores pattern-producing configurations, not patterns as separate entities awaiting recognition.

This matters for Field's problem. If pattern and recognition are unified, then the experiential activation of a pattern-constellation $\\{A\\}$- call it $E(\\{A\\})$ - is phenomenologically primitive. It's an atomic starting point, not something requiring further decomposition into "pattern" and "recognition of pattern."

## From Experience to Language

Pattern-constellations start pre-linguistically. An infant encounters dogs repeatedly. Each encounter involves visual patterns (fur, ears, tail), auditory patterns (barking), tactile patterns (fur texture), motor patterns (petting), and affective patterns (fear or delight). Through Hebbian learning (what fires together wires together), these elements bind into a unified constellation $\{DOG\}$.

This is experiential activation: $E(\{DOG\})$. No language yet. Just structured, multimodal experience.

Language enters when the word-form co-occurs with these experiences. Parents say "dog" when dogs are present. The word-form becomes another element in the constellation through the same learning mechanism. The child now has $E(\{DOG, dog^o\})$ - experiential activations that include the word-form as a label.

Call this the referential or object-word mode: $dog^o$. The word functions as a public label co-occurring with experiential patterns. It's embedded in the constellation through repeated association during actual encounters.

Later, the child learns to use the word linguistically - in sentences, in thought, detached from immediate presence of dogs. "The dog ran away" or "I want a dog" or "All dogs are mammals." All the learned _uses_ of $dog^o$ in language are a pattern of uses, which we call a Linguistic Pattern Constellation (LPC): $<<dog>>$. This pattern of word uses has its own label, $dog^c$; it is simillar to Wittgensteinian "meaning is use" precept: "the concept of dog", which we name $dog^c$, is the totality of possible uses of the word "dog". We call this concept-word mode: $dog^c$[^1]. The same word-form (same token) now operates in abstract linguistic space, enabling communication about absent things, inference, hypotheticals.

We can mark this shift: $\exists(\{DOG, dog^c\})$ indicates linguistic mediation - operations in the conceptual/linguistic domain where the word functions symbolically. mirroring the direct experience $E(\{DOG, dog^o\})$.

The developmental path: $\{A\} \rightarrow \{A, a^o\} \rightarrow \{A, a^c\} \rightarrow \{A, a^o, a^c\}$

Pre-linguistic constellation → constellation with label → differentiation into referential and conceptual modes 

## Reference as Internal Coordination

Here's the key move. What we call "reference" is the operation $\mathcal{R}(x^c, x^o)$ - a two-place mapping that coordinates conceptual deployments with referential activations within the same linguistic system.

When you say  "The dog is in the yard," you're using $dog^c$ - the concept-word mode. Reference is what brings the full $\{DOG\}$ constellation online, activating the experiential patterns that $dog^o$ carries as a label to all experiences with dogs in the pattern constellation. It's not a relation between word and external object. It's a relation between two modes of the same word-form, both embedded in learned constellations.

This dissolves Field's problem. Field worried that reference as a primitive word-world connection posits mysterious non-physical hooks. But $\mathcal{R}(x^c, x^o)$ isn't a word-world connection at all. It's an internal linguistic operation. Both $x^c$ and $x^o$ are aspects of learned representational structures. The coordination between them is implemented in neural weights, activation patterns, and learned associations - all perfectly physical.

The appearance of a word-world gap was an artifact of treating linguistic and experiential aspects as separate kinds of things. They're not. They're parts of the same learned system.

## Connection to real world

This is not to say that any connection with the real world plays no role in language. What is happening is that:
1. In "training", when acquiring language, direct experience is crucial to the formation of the pattern constellation $\{A, a^o\}$. It must be observed that during learning reference has a different mechanism and usually is some sort of ostention, you just indicate what would be labeled $a^o$. It must also be observed that in learning we do build multi-dimensional Pattern Constellations that include visual, feeling, motor and linguistic patterns.
2. Different from how LLMs work today, humans can switch seamlessly from "inference" to learning" whenever there is an encounter with something that activates multiple patterns or none, that is, "something new". You can imagine how the European who first saw a platypus was trying to use words to explain what he was seeing to realize this is a very different process than normal language use.

The main point here is that true connection with the world is episodic after we fully acquired language. This allows us to live in a world that, when we describe it, contains mostly things that are not accessible to our immediate experience.

## Answering Field's Demands

Field demanded naturalistic explanation of reference. Internal reference $\mathcal{R}(x^c, x^o)$ provides one:

**No semantic primitives.** Reference isn't a primitive relation requiring no explanation. It's a learned coordination operation implemented in neural networks through multimodal Hebbian learning and social transmission.[^2]

**Grounded in physics and causation.** Pattern-constellations form through repeated causal encounters. Visual patterns cause retinal activations, auditory patterns cause cochlear responses, words cause auditory activations. Learning mechanisms (Hebbian) are physical processes changing states in real neural networks. The whole story stays within physical-causal vocabulary.

**Empirically tractable.** We can study how children learn words, how neural networks form multimodal associations, how language models develop representations. The architecture of systems like transformers reveals structural parallels to the $x^o/x^c$ distinction. This is testable science, not armchair metaphysics.

**Explains success without correspondence.** Why does reference work? Not because words magically connect to Platonic objects, but because linguistic coordination succeeds when speakers have built sufficiently similar constellations through similar causal histories. Failed coordination triggers correction. Convergence happens through iterated cycles of experiential encounter and linguistic communication.

**Respects Field's analogies.** Just as valence got explained through electron configurations and genes through DNA, reference gets explained through pattern-constellation dynamics. The useful notion "refers" doesn't name a mysterious property but describes a coordination operation in learned representational systems.

# The E/∃ Distinction

The framework distinguishes two realms of operation:

**E - Experiential Activation**: Direct pattern-recognition events. Pre-linguistic or with integrated labels. Operates through attractor dynamics in neural networks. Grounded in sensory-motor-affective patterns. Examples: seeing a dog, hearing barking, feeling fur. Exists in animals and infants. It is what most of the modern phenomenology deals with.

**∃ - Linguistic Mediation**: Conceptual/abstract linguistic use. Can operate detached from immediate experience. Enables communication about absent things, inference, hypotheticals. Creates linguistic pattern-constellations. Examples: "All dogs are mammals," "Bring me a dog," "The dog I saw yesterday."

The transition $E(\{A, a^o\}) \rightarrow \exists(\{A, a^c\})$ captures the move from sensory-grounded to conceptual functioning. This is a developmental achievement in humans, proceeding over years.

Both realms are physically implemented. E-realm involves sensory cortices, motor areas, affective systems. ∃-realm involves language areas, prefrontal cortex, circuits for abstraction and inference. But they remain connected - $\mathcal\{R\}(a^c, a^o)$ brings experiential patterns online when needed.

# Case Studies

## Water on Twin Earth

Putnam's Twin Earth thought experiment: imagine a planet where "water" refers to XYZ instead of H₂O. How do we account for this?

Traditional approaches struggle. If reference is determined purely by causal chains or by speaker intentions or by descriptions, Twin Earth creates puzzles about whether "water" has the same meaning in both places.

PC handles this naturally. $\{WATER\}$ constellations on Earth and Twin Earth form through different causal histories. On Earth, $E(\{WATER, water^o\})$ events involve H₂O molecules interacting with sensory systems. On Twin Earth, they involve XYZ. The learning process produces different pattern-constellations.

The word-form is the same: "water". But $water^o$ on Earth is embedded in $\{WATER, H₂O^c\}$ while $water^o$ on Twin Earth is embedded in $\{WATER, XYZ^c\}$. Reference isn't fixed by the word-form alone, nor by speaker's mental content alone, but by the entire learned constellation including causal-experiential history.

When an Earthling says "water is H₂O," they're coordinating $water^c$ (conceptual use in this sentence) with $water^o$ (which is embedded in $\{WATER\_\{H₂O\}\}$ through their learning history). The reference succeeds because their $\mathcal\{R\}(water^c, water^o)$ operation accesses the right constellation.

Learning is essential. Abstract theories of reference that ignore learning miss what fixes reference - the multimodal causal encounters that build constellations.

## Empty Terms

How does PC handle terms like "phlogiston" that don't refer to anything?

In the 18th century, scientists built $Phlogiston^c$  through theoretical instruction, combustion observations, and linguistic practice. These _linguistic pattern constellation_  were real pattern structures, we can notate $<<phlogiston>>$ - you could learn to use "phlogiston" correctly in chemistry talk.

But $phlogiston^o$ was an illusion, not being properly grounded in experiential activations of actual substances. There was never an activation event of type $E(\{PHLOGISTON\})$ The constellation was built primarily through $\exists(\{PHLOGISTON, phlogiston^c\})$ - linguistic/theoretical operations - without adequate E-grounding. When oxygen theory provided better empirical fit, "phlogiston" was abandoned.

Failed reference happens when constellations lack proper grounding in E-realm. The word-form has conceptual structure (you can use it in sentences) but $\mathcal\{R\}(phlogiston^c, phlogiston^o)$ doesn't successfully activate stable experiential patterns because they don't robustly exist.

This explains referential failure without requiring mysterious word-world connections. Reference fails when internal coordination fails due to inadequate constellation structure.

## Indeterminacy

Quine worried that evidence can't uniquely determine reference. Does "rabbit" refer to rabbits or to undetached rabbit parts or to temporal rabbit-stages? Translation between radically different languages might be indeterminate.

PC expects this. If two speakers build constellations through different learning histories, $\mathcal\{R\}(rabbit^c, rabbit^o)$ might access different structures. Perfect coordination isn't guaranteed by linguistic form alone.

But indeterminacy is bounded. Speakers in the same linguistic community usually build similar constellations because they undergo similar causal-experiential histories. They also build practices that generate certain language-games. When coordination fails (misunderstanding), it shows up in communication breakdown and gets corrected through further interaction.

Field introduced "partial denotation" to handle cases where a term doesn't neatly refer to one thing. PC explains partial denotation: the constellation activated by $\mathcal\{R\}(x^c, x^o)$ might span multiple distinct patterns in the E-realm. "Mass" in pre-relativistic physics activated patterns that split into rest-mass and relativistic-mass under better theory.[^3]

Reference isn't always sharp. Pattern-constellations can be fuzzy, overlapping, or unstable. This is expected when we treat reference as learned coordination rather than primitive connection.

# Neural Implementation

The framework can be implemented in neural networks. Here's one model:

Pattern-constellations as Hopfield networks with Hebbian learning. A Hopfield network stores patterns as low-energy attractor states in a recurrent network. Present a partial pattern (visual features of a dog), and the network completes it (activating auditory, motor, affective elements).

Energy function: $E = -\frac\{1\}\{2\}\sum\_\{i,j\} w\_\{ij\} s\_i s\_j$

where $s\_i$ are neuron states, $w\_\{ij\}$ are connection weights. Learning rule: $\Delta w\_\{ij\} = \eta s\_i s\_j$ (Hebbian).

Each $E(\{A\})$ event adjusts weights, strengthening correlations between co-occurring patterns. After many encounters, $\{A\}$ becomes a stable attractor - a coordinated activation pattern that the network falls into from partial cues.

Adding linguistic labels: when word-form $a^o$ co-occurs with $E(\{A\})$, the phonological/orthographic pattern of $a^o$ becomes another element in the constellation. Weights connect linguistic nodes to sensory-motor-affective nodes.

The $x^o/x^c$ distinction: $a^o$ activates full multimodal constellation. $a^c$ activates primarily linguistic/conceptual nodes with partial connections to experiential nodes. The strength of connections differs.

$\mathcal\{R\}(x^c, x^o)$: the operation that, given activation of $a^c$ (conceptual use), propagates activation through learned weights to bring $a^o$'s full constellation online.

This is testable. We can measure activation patterns in neural networks and brains. Recent work on language models reveals dual structures - "rods" and "caps" - that parallel the $x^o/x^c$ distinction. Rods are thin, specific vectors grounded in multimodal data. Caps are broader semantic neighborhoods supporting linguistic operations.

# Normativity

One worry: if reference is just learned coordination, where does normativity come from? How can reference be correct or incorrect?

The answer lies in attractor dynamics plus social convergence:

**Correctness = stable attractor from E events.** When enough $E(\{X, x^o\})$ events have occurred with consistent patterns, $\{X\}$ forms a stable attractor. Using $x^o$ "correctly" means your use activates patterns consistent with this stable constellation.

**Error = wrong attractor basin.** With insufficient data, your network might fall into a different attractor. You might call cats "dogs" because your $\{DOG\}$ constellation hasn't differentiated properly.

**Correction = more E data.** Additional encounters reveal mismatches. Your $\exists(\{X, x^c\})$ uses fail to coordinate with others' uses. This creates pressure to adjust weights - to modify your constellation until it better matches community norms.

**Collective normativity:** Individual $E(\{X, x^o\})$ events vary. But through $\exists(\{X, x^c\})$ coordination - communication - outliers get revealed. Failed coordination pushes toward convergence. Repeated E/∃ cycles create stable community-level attractors.

No objective arbiter needed. But real constraints exist:

* Attractor stability (E realm)
* Coordination success (∃ realm)
* Collective convergence (E/∃ interaction)

This is naturalistic normativity - standards emerge from physical-causal learning plus social transmission, not from prior semantic facts.

# Implications

## Dissolving the Problem

Field's challenge was: explain reference in naturalistic terms or eliminate it. PC does the first by reconceiving what reference is.

Reference isn't a primitive word-world relation requiring naturalization. It's an internal coordination operation $\mathcal\{R\}(x^c, x^o)$ within learned representational systems. The coordination is implemented through neural weights, Hebbian learning, multimodal association - all physical-causal processes.

The demand for "naturalizing reference" arose from misidentifying reference as a bridge between qualitatively distinct kinds (linguistic vs. worldly). Once we see reference as coordination within a unified learned system, the problem dissolves. We're not connecting separate domains. We're coordinating between modes of pattern-activation in the same distributed network.

Field wanted to avoid semantic primitives, eliminate mysterious hooks, and ground semantics in empirical science. PC delivers:

* No primitive "reference" relation - just learned coordination
* No mysterious hooks - just causal encounters building constellations
* Grounded in neuroscience, developmental psychology, computational modeling
* Testable predictions about learning, neural implementation, cross-linguistic variation

## Comparison to Other Views

This needs serious devlopment, but just as initial considerations:

**Causal theories** (Kripke, Putnam): PC incorporates their insight that reference depends on causal-historical relations. But PC doesn't need a separate theory of "causal chains" connecting words to objects. The chains are just the learning history that builds constellations.

**Descriptivist theories**: PC explains why pure description fails. Reference doesn't go through conceptual specification. But conceptual mode $x^c$ is still important - it coordinates with experiential mode $x^o$ rather than replacing it.

**Intentional theories**: PC naturalizes intentionality the way Field wanted. Mental states are "about" things because mental representations coordinate with experiential pattern-activations. The aboutness is internal coordination, not primitive directedness.

**Deflationary theories**: PC can accept deflationism about truth while explaining reference substantively. Truth might be just a logical device, but reference as coordination operation does real explanatory work.

# Completing Tarski

Tarski was right: truth emerges from simpler semantic facts. Field was right: Tarski's lists don't explain primitive reference.

PC shows why both are correct and why it doesn't matter. Reference is primitive—as internal linguistic coordination, not word-world connection. The $\mathcal\{R\}(x^c, x^o)$ operation needs no further reduction because it's not a bridge but a mode-coordination within already-integrated constellations.

Tarski's framework is complete once we understand what reference actually is. Not mysterious hooks to reality but systematic coordination between experiential and conceptual modes of pattern-constellations. Let's take the "Snow is white" case:

First, what does "snow" refer to? Answer: $\mathcal\{R\}(snow^c, snow^o)$

$\mathcal\{R\}(snow^c, snow^o)$ where $snow^o \in \\{SNOW, snow^o, snow^c\\}$

$\\{SNOW\\}$ formed through $E(\\{SNOW, snow^o\\})$ events:
- Visual: white, crystalline, reflective
- Tactile: cold, wet, granular
- Motor: scooping, throwing, building
- Emotional: winter associations
- Linguistic: $snow^o$, $snow^c$

When $\mathcal\{R\}(snow^c, snow^o)$ operates:
- $snow^c$ (∃ realm) coordinates with $snow^o$ (E realm grounding)
- $snow^o$ activates entire $\\{SNOW\\}$ constellation
- All sensory patterns from $E(\\{SNOW, snow^o\\})$ become active
- This is the grounding

So "Snow is white" is true iff snow is white can be written as:

$$\mathcal\{P\}(white^c, snow^c) \iff white^o \in \\{SNOW\\}$$

$white^o$ is, however, a special "object" like all properties: while it has direct phenomenological perception (and in this sense is object) its manifestation isn't bounded by time or space.


[^1]: Analysis of how sentences with the same word distribute in a LLM _sentence embedding space_, shows that sentences where the word is used in its object-word mode (literal, ostention etc) group more tightly in some sort of "rod", while concept-word sentences disperse widely from them. (an LPC projection of embeddings in 2D or 3D subspace)
[^2]: In Hopfield Networks with Hebbian learning simulations, any learned pattern-constellation $\{A\}$ is, in fact, a low-energy state of the _entire network_, no matter how we define groups of different function neurons.
[^3]: Scientific language is a particular case that we treat elsewhere, arguing that scientific use of words, something we may denote $x^s$, create their specific use patterns, $[x]$, completely distinct from the natural language patterns $<<x>>$. This is something that we see intuitively when we look at how "heat" is used in natural language or in thermodynamics.